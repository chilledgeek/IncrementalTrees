{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparisons\n",
    "\n",
    "In memory and out of memory, using dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dir to repo root if running from repo (rather than pip installed)\n",
    "# (Assuming running from [repo]/notes/)\n",
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "from incremental_trees.trees import StreamingRFC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import dask_ml\n",
    "import dask_ml.datasets\n",
    "from dask_ml.wrappers import Incremental\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_ml.model_selection import train_test_split as dask_tts\n",
    "\n",
    "import dask as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "MAX_ESTIMATORS = 60  # Lower to run faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n"
     ]
    }
   ],
   "source": [
    "# Prepare dask cluster\n",
    "cluster = LocalCluster(processes=False,\n",
    "                       n_workers=2,\n",
    "                       threads_per_worker=2,\n",
    "                       scheduler_port=8383,\n",
    "                       diagnostics_port=8484)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data, in memory\n",
    "\n",
    "Compare increasing estimators with RandomForest (using warm_start) against Incremental StreamingRFC (dask handles .partial_fit).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n"
     ]
    }
   ],
   "source": [
    "x, y = dask_ml.datasets.make_blobs(n_samples=1e5,\n",
    "                                   chunks=1e4,\n",
    "                                   random_state=0,\n",
    "                                   n_features=40,\n",
    "                                   centers=2,\n",
    "                                   cluster_std=100)\n",
    "\n",
    "x_dd = dd.dataframe.from_array(x, \n",
    "                               chunksize=1e4)\n",
    "y_dd = dd.dataframe.from_array(y,\n",
    "                               chunksize=1e4)\n",
    "\n",
    "x_pd = pd.DataFrame(x.persist().compute())\n",
    "y_pd = pd.DataFrame(y.persist().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.517654418945312"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pd.memory_usage(deep=True).sum() / 1024 /1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n"
     ]
    }
   ],
   "source": [
    "def score(mod, \n",
    "          train: Tuple[np.array, np.array],\n",
    "          test: Tuple[np.array, np.array],\n",
    "          pr=False) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Return ROC auc on x_train and x_test (from caller) on mod. Print if requested.\n",
    "    \"\"\"\n",
    "    y_pred_train_proba = mod.predict_proba(train[0])[:, 1]\n",
    "    y_pred_test_proba = mod.predict_proba(test[0])[:, 1]\n",
    "\n",
    "    roc_train = roc_auc_score(train[1], y_pred_train_proba)\n",
    "    roc_test = roc_auc_score(test[1], y_pred_test_proba)\n",
    "    if pr:\n",
    "        print(f\"n_ests: {len(rfc.estimators_)}\")\n",
    "        print(f'Train AUC: {roc_train}')\n",
    "        print(f'Test AUC: {roc_test}')\n",
    "        \n",
    "    return roc_train, roc_test\n",
    "\n",
    "\n",
    "def score_dask(mod, \n",
    "               train: Tuple[np.array, np.array],\n",
    "               test: Tuple[np.array, np.array],\n",
    "               pr=False) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Score model using available dask metric (accuracy)\n",
    "    \"\"\"\n",
    "    roc_train = mod.score(train[0], train[1])\n",
    "    roc_test = mod.score(test[0], test[1])\n",
    "    if pr:\n",
    "        print(f\"n_ests: {len(rfc.estimators_)}\")\n",
    "        print(f'Train AUC: {roc_train}')\n",
    "        print(f'Test AUC: {roc_test}')\n",
    "        \n",
    "    return roc_train, roc_test\n",
    "\n",
    "\n",
    "def multiple_fit(x: np.array, y: np.array,\n",
    "                 steps=np.arange(1, 101, 2),\n",
    "                 sample: int=1):\n",
    "    \"\"\"\n",
    "    Fit a random forest model with an increasing number of estimators.\n",
    "    \n",
    "    This version doesn't use warm start and refits the model from scratch each iteration.\n",
    "    This is for the sake of comparing timings to dask function below.\n",
    "    \n",
    "    :param steps: Range to iterate over. Sets total number of estimators that will be fit in model\n",
    "                  after each iteration. Should be range with constant step size.\n",
    "    :param sample: Proportion of randomly sampled training data to use on each partial_fit call.\n",
    "                   If sample = 1, all training data is used on each interation,\n",
    "                   so should behave as standard random forest. Default = 1 (100%).\n",
    "    \"\"\"\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state=1)\n",
    "    \n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    for s in steps:\n",
    "        \n",
    "        # Fit full model on each iteration\n",
    "        rfc = RandomForestClassifier(warm_start=False)\n",
    "        \n",
    "        # Fit model with these n ests\n",
    "        rfc.set_params(n_estimators=s)\n",
    "        rfc.fit(x_train, y_train)\n",
    "        \n",
    "        tr_score, te_score = score(rfc, \n",
    "                                   train=(x_train, y_train),\n",
    "                                   test=(x_test, y_test),\n",
    "                                   pr=False)\n",
    "        \n",
    "        train_scores.append(tr_score)\n",
    "        test_scores.append(te_score)\n",
    "    \n",
    "    return rfc, train_scores, test_scores\n",
    "\n",
    "\n",
    "def plot_auc(steps, train_scores, test_scores):\n",
    "    \"\"\"\n",
    "    Plot the train and test auc scores vs total number of model estimators\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    plt.plot(steps, train_scores)\n",
    "    plt.plot(steps, test_scores)\n",
    "    plt.xlabel('n_estimators')\n",
    "    plt.ylabel('auc')\n",
    "    plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.arange(1, MAX_ESTIMATORS, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 30s, sys: 1.02 s, total: 3min 31s\n",
      "Wall time: 3min 37s\n",
      "With 57: 1.0 | 0.6337612567122703\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAELCAYAAAD3MhIJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHP9JREFUeJzt3Xt4XXWd7/H3N5c2vV+S3tPSKBVbuQQI5XpGLiJtHQuIVorMox61OMrIeEZGekYZ5Hl8xGdGRx0RB7GiR2lBOEiVHmnBIo7cmkIKpS1t6S1poQ2l6ZW0TfI9f/xW2t2QljRda6/svT+v59ld1+z9TZP9yVq/tX6/be6OiEhcitIuQETyi0JFRGKlUBGRWClURCRWChURiZVCRURipVARkVgpVEQkVgoVEYlVSdoFHK+KigofP3582mWIFJylS5e+6e7D3m2/nAuV8ePHU1tbm3YZIgXHzDZ2ZT+d/ohIrBQqIhIrhYqIxEqhIiKxUqiISKwSCxUzm2Nm28xs+VG2m5n9yMzWmtlLZnZWUrWISPYkeaRyLzDlGNunAhOixyzgrgRrEZEsSew+FXd/yszGH2OXK4FfeRjP8lkzG2xmo9z99aRqyrbWNmd/Syv7D7bR3HF6sJX9LYenbe64gxNNHRxwdxwgcxscse/RHHOgUA0jKpG+vUq45uzK2J4vzZvfxgD1GcsN0bp3hIqZzSIczTBu3LisFNdVjbv3s3jVNhat3MqKLbuOCJGDrXrjSs83ZnCfvAmVLnP3u4G7AWpqalJ9p7o7q7fu4fGVW3l85Vbq6ptwh9GDyjinaij9epdQVlJM79KijGkRvUuLKSstonfJ4WnvkiLKSovpVVJEcZFhgFn7FAzDLLyuWefbDKJ/OmfH2GjH+DopHEUx/yKkGSqbgbEZy5XRuh7nYGsbz69/61CQ1L/1NgCnVw7iqx96H5dNHM6kUQMxvUtFUg2V+cCNZjYPOBfY2ZPaU3buO8iTq7exaMVW/ry6kd3NLfQuKeLCkyv4+w+ezGUThzNiYFnaZYr0OImFipnNBS4GKsysAfhXoBTA3X8KLACmAWuBfcBnk6rleDxSt5m5z29iyYYdtLY5Ff17MfXUkXxo4ggumlBB3145ccYokpokr/7MfJftDnw5qdfvjq27mrlpXh1VFf244W/ew4cmjaC6cjBFRTqtEekq/dnN8OKmJgC+N+MMzho3JOVqRHKTbtPPUFffRGmxMWnUwLRLEclZCpUMdfU7mDhqIGWlxWmXIpKzFCqR1jbn5YadVI8dnHYpIjlNoRJZs203ew+0KlRETpBCJVIXNdIqVEROjEIlsqyhiYFlJVRV9Eu7FJGcplCJvLipiTPGDtat9iInSKEC7N3fwuqtuzlTpz4iJ0yhAry8eSdtDtXjFCoiJ0qhQrjpDeCMSoWKyIlSqBCu/Iwb2pfy/r3TLkUk5ylUCFd+dClZJB4FHypbdzXz+s5mzlCoiMSi4EPlRd30JhKrgg+V9p7JHxitnskicVCoqGeySKwKOlTUM1kkfgUdKuqZLBK/gg6VZfVqpBWJW0GHSl196Jk8vlw9k0XiUtCh0t4zWaPli8SnYENFPZNFklGwoaKeySLJKNhQUc9kkWQUbqioZ7JIIgo2VJY1NKkToUgCCjJU2nsm6/4UkfgVZKioZ7JIcgoyVNQzWSQ5BRoq6pkskpSCCxX1TBZJVqKhYmZTzOxVM1trZrd0sv0kM3vCzF4ysyfNrDLJegDWbtvD3gOtuj9FJCGJhYqZFQN3AlOBScBMM5vUYbd/B37l7qcDtwPfSaqednX1OwDdSSuSlCSPVCYDa919nbsfAOYBV3bYZxLwp2h+cSfbY9feM7lKPZNFEpFkqIwB6jOWG6J1mZYBH4vmrwYGmFl5gjWpZ7JIwtJuqP0a8EEzexH4ILAZaO24k5nNMrNaM6ttbGzs9oupZ7JI8pIMlc3A2IzlymjdIe6+xd0/5u5nAv8SrWvq+ETufre717h7zbBhw7pdkHomiyQvyVBZAkwwsyoz6wVcC8zP3MHMKsysvYbZwJwE61HPZJEsSCxU3L0FuBF4DFgJPODur5jZ7WY2PdrtYuBVM1sNjAC+nVQ9EMakHTu0j3omiySoJMknd/cFwIIO627NmH8QeDDJGjLV1TdRM35otl5OpCCl3VCbNeqZLJIdBRMq6pkskh0FEyrqmSySHQUUKuqZLJINBREq7T2TdSlZJHkFESrtPZPVniKSvIIIFfVMFsmeAgkV9UwWyZaCCBX1TBbJnrwPFfVMFsmuvA+V9p7J+uAwkezI+1BZVq87aUWyKe9DpU49k0WyqiBCpXrskLTLECkYeR0q6pkskn15HSrqmSySfXkdKnX1TZQUqWeySDbldagsq29Sz2SRLMvbUGltc15qaNKpj0iW5W2oqGeySDryNlTUM1kkHXkcKuqZLJKGvA0V9UwWSUdehkp7z2S1p4hkX16GyvL2z0xWqIhkXV6GSp16JoukJi9DpaJ/b6adNlI9k0VSkOhnKaflmrMruebsyrTLEClIeXmkIiLpUaiISKwUKiISK4WKiMRKoSIisUo0VMxsipm9amZrzeyWTraPM7PFZvaimb1kZtOSrEdEkpdYqJhZMXAnMBWYBMw0s0kddvsG8IC7nwlcC/wkqXpEJDuSPFKZDKx193XufgCYB1zZYR8H2sd6HARsSbAeEcmCJENlDFCfsdwQrct0G3C9mTUAC4B/6OyJzGyWmdWaWW1jY2MStYpITNJuqJ0J3OvulcA04P+Y2Ttqcve73b3G3WuGDRuW9SJFpOuSDJXNwNiM5cpoXabPAQ8AuPszQBlQkWBNIpKwJENlCTDBzKrMrBehIXZ+h302AZcBmNlEQqjo/EYkhyUWKu7eAtwIPAasJFzlecXMbjez6dFu/wR8wcyWAXOBz7i7J1WTiCQv0V7K7r6A0ACbue7WjPkVwIVJ1iAi2ZV2Q62I5BmFiojESqEiIrHqUqiY2XlmNiBjeaCZnZtcWSKSq7p6pHIXsCdjeU+0TkTkCF0NFcu81OvubeTp+LYicmK6GirrzOwrZlYaPW4C1iVZmIjkpq6GyheBCwi32TcA5wKzkipKRHJXl05h3H0b4TZ7EZFj6lKomNkvCGOfHMHd/2fsFYlITutqY+sfMubLgKvRgEoi0omunv48lLlsZnOB/06kIhHJad29o3YCMDzOQkQkP3S1TWU3h9tUHNgK/HNSRYlI7urq6c8AMxtKOEIpa1+dWFUikrO6eqTyeeAmwpCQdcB5wDPApcmVJiK5qKttKjcB5wAb3f0S4EygKbGqRCRndTVUmt29GcDMerv7KuCU5MoSkVzV1ftUGsxsMPA7YJGZ7QA2JleWiOSqrjbUXh3N3mZmiwmfJvjHxKoSkZx13MMXuPufkyhERPKDhpMUkVgpVEQkVgoVEYmVQkVEYqVQEZFYKVREJFYKFRGJlUJFRGKlUBGRWClURCRWChURiVWioWJmU8zsVTNba2a3dLL9P8ysLnqsNjON0SKS4xL7PGQzKwbuBC4nfKrhEjOb7+4r2vdx969m7P8PhMGfRCSHJXmkMhlY6+7r3P0AMA+48hj7zwTmJliPiGRBkqEyBqjPWG6I1r2DmZ0EVAF/SrAeEcmCntJQey3woLu3drbRzGaZWa2Z1TY2Nma5NBE5HkmGymZgbMZyZbSuM9dyjFMfd7/b3WvcvWbYsGExligicUsyVJYAE8ysysx6EYJjfsedzOz9wBDCR36ISI5LLFTcvQW4EXgMWAk84O6vmNntZjY9Y9drgXnurg8nE8kDiV1SBnD3BcCCDutu7bB8W5I1iEh29ZSGWhHJEwoVEYmVQkVEYqVQEZFYKVREJFYKFRGJlUJFRGKlUBGRWClURCRWChURiZVCRURipVARkVgpVEQkVgoVEYmVQkVEYqVQEZFYKVREJFYKFRGJlUJFRGKlUBGRWClURCRWiY6mLyI91MFmeOs1eHMNHNwH1dfF9tQKFZF85Q57tsGbq2H7mhAgb64Jy02bgOijtvoNU6iIJG7/7vCGbGuB1oPQdhBaW6LpwbC+s23t64tKoaQMSnpnPMoOT4t7RcuZ6zLeju7Q1nr4+bz1yOVD89G0dT/s2BgFyNowfXMN7N91+DlL+0L5yVBZE0Kk/GSoeB+UvzfW/zqFihSug82wY314E25/LUzfWheme7Zmvx4rgqKSKETauv88A8dAxQQ4/ZMhNCqi8BgwGoqSb0ZVqEh+a22Bpo0hNN6KgmP7Wti+DnbWc+gUAKDf8PBXe8LlMPS9MHA0FJeGo472aVFxxrqSaF1JtC6aWnEIhpb90NKcMW2G1gMd1nWYth/lFJWE1yoqjuZLMtaVhNfIXFdcCoPGhqOP3v1T++8GhYrkA3fYtz0c7re3HWxfG6Y71oc3arveg0JwjDsPyj8V3oRD3xPWlQ1K73vIIwoVyR0Hm6PTk4zgaA+P5qbD+xX3Ckcaw06BiX8L5RNCaJSfDH3LwSy976EAKFSkZ3APwbBrC+zcDLuiR/v8jg3hdCWzrWHAqBAUp34sBEfFhLA8eFw4JZBUKFQkO1pbwlFG06Z3Bkb7/MG9R36NFYXgGDgaxpwNZ1wbhcfJUdvBgHS+FzkmhYrEb/9u2LoC3ngJ3ng5PLatCA2RhxgMGBkCY9j74eQPhfmBY2BQZZjvP/LIy6ySE/QTk+5zh92vR8GRESBvrefQVZU+Q2DkaXDO52HEqTC0KgTGgFHhioXkHYWKdN3urbDpadi89HCA7Nt+ePuQqhAgZ1wHI08N8wPHqGG0wCQaKmY2BfghUAzc4+53dLLPDOA2wp+2Ze4e3/3C0n3u4XLsxmdg49MhTN5aF7YV94bhE+GUaTDy9BAeIz4AZQPTrVl6hMRCxcyKgTuBy4EGYImZzXf3FRn7TABmAxe6+w4zG55UPfIu2lpDu8fGZ0KAbHwG9rwRtvUZAuPOh7M/CyddAKPO0KmLHFWSRyqTgbXuvg7AzOYBVwIrMvb5AnCnu+8AcPdtCdYjmVoOwJYXowB5GjY9B/t3hm0DK6Hqf4QgOekCqDglK7d3S35IMlTGAPUZyw3AuR32eR+Amf2VcIp0m7v/seMTmdksYBbAuHHjEik2Jx3YF+7f2L8LmndC864QDM27onXR+vb5zHUHdh9+nor3wQeuCgFy0gXhPg+Rbkq7obYEmABcDFQCT5nZae7elLmTu98N3A1QU1PjHZ+kIBzYGxpGt9TB63Vh+uarR+94VlQa2jh6DwzTskHQ7z1h2jtaHnlqOBrpV5Hd70XyWpKhshkYm7FcGa3L1AA85+4HgfVmtpoQMksSrKvn278nBEh7eLxeF7qytwdI/xEwqhomTQ9HGX2GZIRFFCSlfXTVRVKRZKgsASaYWRUhTK4FOl7Z+R0wE/iFmVUQTofWJVhTz9OyP7RtbH4h4whkNYfu8+g/EkZXw6SrwnRUNQwclWrJIseSWKi4e4uZ3Qg8RmgvmePur5jZ7UCtu8+Ptn3YzFYArcDN7r796M+aB/bvgYbnQ+PoxqehoTYMsAPhhrBR1aEvy6jqECIDRqZbrxxy8OBBGhoaaG5ufvedc1hZWRmVlZWUlnbvCp+551YTRU1NjdfW1qZdRtftews2PQsb/xpC5PVlYRQvKw6XZk+6ILRrVNYoQHq49evXM2DAAMrLy7E8PbV0d7Zv387u3bupqqo6YpuZLXX3mnd7jrQbavPPrtcPX6bd+HS49wPCDWOVNXDRV0OQjJ2sDnE5prm5mfHjx+dtoACYGeXl5TQ2Nnb7ORQqcXCHpb+Av/4o3IUK0Ks/jD03nMqcdCGMPgtKy9KtU05YPgdKuxP9HhUqJ+rg2/CHr8KyueE05pzPhyORkaerh63Eqqmpifvuu48vfelLx/V106ZN47777mPw4MEJVXYk/dafiB0b4P6/C5d/L/7f8Dc3685TSUxTUxM/+clP3hEqLS0tlJQc/a28YMGCpEs7gkKlu9Y+Dg99Ptw7ct398L4r0q5I8twtt9zCa6+9RnV1NaWlpZSVlTFkyBBWrVrF6tWrueqqq6ivr6e5uZmbbrqJWbNmATB+/Hhqa2vZs2cPU6dO5aKLLuLpp59mzJgxPPLII/Tp0yfWOhUqx6utDf77e/Cnb8PwSXDtr8PAyVJQvvX7V1ixZde773gcJo0eyL9+9ANH3X7HHXewfPly6urqePLJJ/nIRz7C8uXLD12lmTNnDkOHDuXtt9/mnHPO4ZprrqG8vPyI51izZg1z587lZz/7GTNmzOChhx7i+uuvj/X7UKgcj+ad8PDfw6uPwmmfgI/+EHr1S7sqKVCTJ08+4rLvj370Ix5++GEA6uvrWbNmzTtCpaqqiurqagDOPvtsNmzYEHtdCpWu2rYK7v9UGNVsyh1w7hd1G3wBO9YRRbb063f4D9qTTz7J448/zjPPPEPfvn25+OKLO71Jr3fv3ofmi4uLefvtt2OvS6HSFa88DL/7cjgq+fTvYfyFaVckBWjAgAHs3r270207d+5kyJAh9O3bl1WrVvHss89mubrDFCrH0toCT9wGT/8nVE6GGb9SvxtJTXl5ORdeeCGnnnoqffr0YcSIEYe2TZkyhZ/+9KdMnDiRU045hfPOOy+1OnWb/tHsaYQHPwsb/hLuPbniO1DSK/nXlR5r5cqVTJw4Me0ysqKz71W36Z+IhqXwwN+FQZ2vuguqNWyuSFcpVDpa+ktY8LXQue9zC0OnPxHpMoVKu7Y2ePzW0H7y3kvhmp9D36FpVyWScxQqEPrvPHwDrHgEzvkCTP2uPotXpJsUKnvfhLkzoWEJfPjbcP6Xdf+JyAko7FDZ/hr85uOwawvM+CVMujLtikRyXuF2qd30HNzzoXDr/ad/r0CRHq+9l3J3/OAHP2Dfvn0xV9S5wgyVVx6GX34U+gyGzy0Ko7CJ9HC5EiqFdfrjHq7uLPomjD0Prr0P+pW/+9eJ9ACZQx9cfvnlDB8+nAceeID9+/dz9dVX861vfYu9e/cyY8YMGhoaaG1t5Zvf/CZbt25ly5YtXHLJJVRUVLB48eJE6yycUGltgT9+HZbcEz7u4ur/0vCO0n3/75YwOFecRp4GU+846ubMoQ8WLlzIgw8+yPPPP4+7M336dJ566ikaGxsZPXo0jz76KBD6BA0aNIjvf//7LF68mIqK5D84rjBOfw7sDT2Ml9wDF3wFPv4LBYrktIULF7Jw4ULOPPNMzjrrLFatWsWaNWs47bTTWLRoEV//+tf5y1/+wqBBg7JeW/4fqex+A+77JLzxEnzke6Efj8iJOsYRRTa4O7Nnz+aGG254x7YXXniBBQsW8I1vfIPLLruMW2+9Nau15feRyraV4QrPm2tg5jwFiuS0zKEPrrjiCubMmcOePXsA2Lx5M9u2bWPLli307duX66+/nptvvpkXXnjhHV+btPw9Uln/FMy7PpzmfPZRGH1m2hWJnJDMoQ+mTp3Kddddx/nnnw9A//79+fWvf83atWu5+eabKSoqorS0lLvuuguAWbNmMWXKFEaPHp14Q21+Dn2w7H545MtQfjJ86rcweOyx9xfpAg19UMhDH1hR+OydGb8K96KISNbkZ6ic/gk49Rp9Bo9ICvL3XadAEUmF3nkixyHX2iC740S/R4WKSBeVlZWxffv2vA4Wd2f79u2UlXX/5tD8bFMRSUBlZSUNDQ00NjamXUqiysrKqKys7PbXJxoqZjYF+CFQDNzj7nd02P4Z4N+AzdGqH7v7PUnWJNJdpaWlR3wioHQusVAxs2LgTuByoAFYYmbz3X1Fh13vd/cbk6pDRLIryTaVycBad1/n7geAeYBGQhLJc0mGyhigPmO5IVrX0TVm9pKZPWhmuvVVJMel3VD7e2Cuu+83sxuAXwKXdtzJzGYBs6LFPWb26lGerwJ4M5FKu0f1HFtPqwd6Xk09qZ6TurJTYn1/zOx84DZ3vyJang3g7t85yv7FwFvu3u0BIMystit9E7JF9RxbT6sHel5NPa2erkjy9GcJMMHMqsysF3AtMD9zBzPL/LTz6cDKBOsRkSxI7PTH3VvM7EbgMcIl5Tnu/oqZ3Q7Uuvt84CtmNh1oAd4CPpNUPSKSHYm2qbj7AmBBh3W3ZszPBmbH+JJ3x/hccVA9x9bT6oGeV1NPq+dd5dx4KiLSs6nvj4jEKi9CxcymmNmrZrbWzG5JqYY5ZrbNzJZnrBtqZovMbE00HZLFesaa2WIzW2Fmr5jZTWnWZGZlZva8mS2L6vlWtL7KzJ6Lfnb3R436WWNmxWb2opn9Ie16zGyDmb1sZnVmVhutS+13qLtyPlQyugNMBSYBM81sUgql3AtM6bDuFuAJd58APBEtZ0sL8E/uPgk4D/hy9P+SVk37gUvd/QygGphiZucB3wX+w91PBnYAn8tSPe1u4sirjmnXc4m7V2dcRk7zd6h73D2nH8D5wGMZy7OB2SnVMh5YnrH8KjAqmh8FvJri/9MjhH5YqdcE9AVeAM4l3NhV0tnPMgt1VBLeqJcCfwAs5Xo2ABUd1qX+8zreR84fqdD17gBpGOHur0fzbwAj0ijCzMYDZwLPpVlTdKpRB2wDFgGvAU3u3hLtku2f3Q+AfwbaouXylOtxYKGZLY3uIoce8jt0PNK+Tb9guLubWdYvtZlZf+Ah4B/dfZeZpVaTu7cC1WY2GHgYeH+2XrsjM/tbYJu7LzWzi9Oqo4OL3H2zmQ0HFpnZqsyNaf0OHa98OFLZDGR2RKzk8PgsadvaftdwNN2WzRc3s1JCoPzG3f9vT6gJwN2bgMWE04vBZtb+xy2bP7sLgelmtoHQg/5Swtg/adWDu2+OptsIoTuZHvDzOl75ECrv2h0gRfOBT0fznya0a2SFhUOSnwMr3f37addkZsOiIxTMrA+hfWclIVw+nu163H22u1e6+3jC78yf3P1TadVjZv3MbED7PPBhYDkp/g51W9qNOjE1cE0DVhPO0f8lpRrmAq8DBwnn4p8jnKM/AawBHgeGZrGeiwjn6C8BddFjWlo1AacDL0b1LAdujda/B3geWAv8Fuidws/uYuAPadYTve6y6PFK++9xmr9D3X3ojloRiVU+nP6ISA+iUBGRWClURCRWChURiZVCRURipVARkVgpVCQWZlZtZtMylqfHNQyFmf2jmfWN47kkebpPRWIRfYRtjSfwaZPRrfQ17t7lj6ows2IPfY0ky3SkUmDMbLyZrTSzn0WDJS2MbpvvbN/3mtkfo16zfzGz90frP2Fmy6MBl56KukfcDnwyGmDok2b2GTP7cbT/vWZ2l5k9a2brzOziaFCrlWZ2b8br3WVmtR0GcfoKMBpYbGaLo3Uzo8GMlpvZdzO+fo+Zfc/MlgHnm9kd0SBVL5nZvyfzPyrvkPYtvXpk90EY86UFqI6WHwCuP8q+TwATovlzCf1jAF4GxkTzg6PpZ4AfZ3ztoWXCAFbzCOOVXAnsAk4j/FFbmlHL0GhaDDwJnB4tbyAaZ4QQMJuAYYRe9n8Croq2OTAjmi8njEVimXXqkfxDRyqFab2710XzSwlBc4RoyIQLgN9GY6D8F2GQIIC/Avea2RcIAdAVv/fw7n4Z2OruL7t7G6GfS/vrzzCzFwh9hD5AGMmvo3OAJ9290cO4J78B/iba1krolQ2wE2gGfm5mHwP2dbFOOUEaT6Uw7c+YbwU6O/0pIgxYVN1xg7t/0czOBT4CLDWzs4/jNds6vH4bUGJmVcDXgHPcfUd0WlTWhefN1OxRO4qHz52aDFxG6HV8I518pK7ET0cq0il33wWsN7NPQBhKwczOiObf6+7PefgMp0bCeDa7gQEn8JIDgb3ATjMbQRhzuF3mcz8PfNDMKqLxiWcCf+74ZNGR1iAPnz31VeCME6hNjoOOVORYPgXcZWbfAEoJ7SLLgH8zswmENpInonWbgFuiU6VOPy/7WNx9mZm9CKwiDA/614zNdwN/NLMt7n5JdKl6cfT6j7p7Z2OMDAAeMbOyaL//dbw1SffokrKIxEqnPyISK53+CGZ2J2HM1kw/dPdfpFGP5Dad/ohIrHT6IyKxUqiISKwUKiISK4WKiMRKoSIisfr/pCPlFP/s/+8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(warm_start=True)\n",
    "\n",
    "%time rfc, train_scores, test_scores = multiple_fit(x_pd.values, y_pd.values.squeeze(), steps=steps)\n",
    "\n",
    "print(f\"With {len(rfc.estimators_)}: {train_scores[-1]} | {test_scores[-1]}\")\n",
    "plot_auc(steps, train_scores, test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single incremental forest specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 7500, 7500, 7500, 7500, 7500, 7500, 7500, 7500, 7500), (40,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = dask_tts(x, y, \n",
    "                                            test_size=0.25)\n",
    "\n",
    "x_train.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incremental forest\n",
    "1 estimator per subset, 10 % per chunk, 1 pass through data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 92] Protocol not available\n",
      "/mnt/s/OneDrive/Matlab/dask tests/IncrementalTrees/incremental_trees/trees.py:199: RuntimeWarning: invalid value encountered in true_divide\n",
      "  norm_prob = preds / counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ests: 57\n",
      "Train AUC: 0.6658850266643547\n",
      "Test AUC: 0.566714711139625\n"
     ]
    }
   ],
   "source": [
    "srfc = Incremental(StreamingRFC(n_estimators_per_chunk=1,\n",
    "                                max_n_estimators=np.inf))\n",
    "\n",
    "srfc.fit(x_train, y_train,\n",
    "         classes=[0, 1])\n",
    "\n",
    "tr_score, te_score = score(srfc, \n",
    "                           train=(x_train, y_train),\n",
    "                           test=(x_test, y_test),\n",
    "                           pr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incremental forest\n",
    "20 estimators per subset (different features), 10 % per chunk, 1 pass through data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ests: 57\n",
      "Train AUC: 0.8403617676637958\n",
      "Test AUC: 0.6507955222895951\n"
     ]
    }
   ],
   "source": [
    "srfc = Incremental(StreamingRFC(n_estimators_per_chunk=20,\n",
    "                                max_n_estimators=np.inf))\n",
    "\n",
    "srfc.fit(x_train, y_train,\n",
    "         classes=[0, 1])\n",
    "\n",
    "tr_score, te_score = score(srfc, \n",
    "                           train=(x_train, y_train),\n",
    "                           test=(x_test, y_test),\n",
    "                           pr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forest of partial decision trees\n",
    "1 estimator per subset with all features, 10 % per chunk, 1 pass through data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ests: 57\n",
      "Train AUC: 0.6702321483770426\n",
      "Test AUC: 0.5732644847212355\n"
     ]
    }
   ],
   "source": [
    "srfc = Incremental(StreamingRFC(n_estimators_per_chunk=1,\n",
    "                                max_n_estimators=np.max(steps),\n",
    "                                max_features=x.shape[1]))\n",
    "\n",
    "srfc.fit(x_train, y_train,\n",
    "         classes=[0, 1])\n",
    "\n",
    "tr_score, te_score = score(srfc, \n",
    "                           train=(x_train, y_train),\n",
    "                           test=(x_test, y_test),\n",
    "                           pr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forest of partial decision trees\n",
    "20 estimator per subset with all features, 10 % per chunk, 1 pass through data.\n",
    "\n",
    "Extra estimators shouldn't help here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ests: 57\n",
      "Train AUC: 0.7542754850739607\n",
      "Test AUC: 0.6273808721369764\n"
     ]
    }
   ],
   "source": [
    "srfc = Incremental(StreamingRFC(n_estimators_per_chunk=20,\n",
    "                                max_n_estimators=np.max(steps),\n",
    "                                max_features=x.shape[1]))\n",
    "\n",
    "srfc.fit(x_train, y_train,\n",
    "         classes=[0, 1])\n",
    "\n",
    "tr_score, te_score = score(srfc, \n",
    "                           train=(x_train, y_train),\n",
    "                           test=(x_test, y_test),\n",
    "                           pr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n estimators per chunk vs performance\n",
    "\n",
    "Effect of increasing estimators per subset (with different set ups)\n",
    "\n",
    "Function here add Incremental to supplied model, and uses .fit to refit the full model in each iteration.\n",
    "\n",
    "The other functions (above and in PerformanceComparisons.ipynb) do incremental fits using warm start (either directly or via .partial_fit). \n",
    "\n",
    "This means the timing information cannot be directly compared!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_dask_fit(x: np.ndarray, y:np.ndarray,\n",
    "                      steps=np.arange(1, 101, 2),\n",
    "                      **kwargs) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Fit increasing number of estimators using .partial_fit on a subsample of the training data.\n",
    "    Uses Dask by adding Incremental to model and calling fit. This refits the whole model one each\n",
    "    iteration, so will be slower than the other test functions. Timing this function can only be compared\n",
    "    to other calls of this function.\n",
    "    \n",
    "    The data passed to the Random forest fit by partial_fit is handled by dask and is sequential batches\n",
    "    of data, rather than random samples (as used by inc_partial_fit in PerformanceComparisons.ipynb).\n",
    "    \n",
    "    StreamingRFC.n_estimators: Number of estimators that will be fit in each step. Set from first\n",
    "                               difference in range (ie. range[1]-range[0])\n",
    "    StreamingRFC.max_n_estimators: Limit on number of estimators than will be fit in model. Should >\n",
    "                                   range[-1].\n",
    "    \n",
    "    :param steps: Range to iterate over. Sets total number of estimators that will be fit in model\n",
    "                  after each iteration. Should be range with constant step size.\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    x_train, x_test, y_train, y_test = dask_tts(x, y, \n",
    "                                               test_size=0.25)\n",
    "    \n",
    "    n_train = x_train.shape[0]\n",
    "    \n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    for s in steps:\n",
    "        \n",
    "        # Create fresh model each iteration\n",
    "        srfc_ = StreamingRFC(n_estimators_per_chunk=s,\n",
    "                             max_n_estimators=np.inf,\n",
    "                             **kwargs)\n",
    " \n",
    "           \n",
    "        # Add Incremental\n",
    "        srfc_ = Incremental(srfc_)\n",
    "        \n",
    "        # Fit model with these n ests\n",
    "        # From scratch each time\n",
    "        srfc_.fit(x_train, y_train,\n",
    "                  classes=[0, 1])\n",
    "        \n",
    "        tr_score, te_score = score(srfc_,\n",
    "                                   train=(x_train, y_train),\n",
    "                                   test=(x_test, y_test),\n",
    "                                   pr=False)\n",
    "        train_scores.append(tr_score)\n",
    "        test_scores.append(te_score)\n",
    "    \n",
    "    return srfc_, train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incremental forest\n",
    "*range* estimators per subset (different features), 10 % per chunk, 1 pass through data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object StreamingRFC(bootstrap=True, class_weight=None, criterion='gini',\n       max_depth=None, max_features='auto', max_leaf_nodes=None,\n       max_n_estimators=inf, min_impurity_decrease=0.0,\n       min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n       min_weight_fraction_leaf=0.0, n_estimators=1,\n       n_estimators_per_chunk=1, n_jobs=None, oob_score=False,\n       random_state=None, verbose=0, warm_start=True), as the constructor either does not set or modifies parameter n_estimators",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-af5f24d060e6>\u001b[0m in \u001b[0;36mmultiple_dask_fit\u001b[0;34m(x, y, steps, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# From scratch each time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         srfc_.fit(x_train, y_train,\n\u001b[0;32m---> 45\u001b[0;31m                   classes=[0, 1])\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         tr_score, te_score = score(srfc_,\n",
      "\u001b[0;32m/mnt/s/OneDrive/Matlab/dask tests/IncrementalTrees/pc_env_linux/lib/python3.6/site-packages/dask_ml/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_for_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/s/OneDrive/Matlab/dask tests/IncrementalTrees/pc_env_linux/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     71\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     72\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object StreamingRFC(bootstrap=True, class_weight=None, criterion='gini',\n       max_depth=None, max_features='auto', max_leaf_nodes=None,\n       max_n_estimators=inf, min_impurity_decrease=0.0,\n       min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n       min_weight_fraction_leaf=0.0, n_estimators=1,\n       n_estimators_per_chunk=1, n_jobs=None, oob_score=False,\n       random_state=None, verbose=0, warm_start=True), as the constructor either does not set or modifies parameter n_estimators"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final_est' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a540e9c2ab24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final_est, train_scores, test_scores = multiple_dask_fit(x, y, steps=steps)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"With {len(final_est.estimators_)}: {train_scores[-1]} | {test_scores[-1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplot_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_est' is not defined"
     ]
    }
   ],
   "source": [
    "steps = np.arange(1, MAX_ESTIMATORS, 6)\n",
    "\n",
    "%time final_est, train_scores, test_scores = multiple_dask_fit(x, y, steps=steps)\n",
    "print(f\"With {len(final_est.estimators_)}: {train_scores[-1]} | {test_scores[-1]}\")\n",
    "plot_auc(steps, train_scores, test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forest of partial decision trees\n",
    "*range* estimators per subset with all features, 10 % per chunk, 1 pass through data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.arange(1, MAX_ESTIMATORS, 6)\n",
    "\n",
    "%time final_est, train_scores, test_scores = multiple_dask_fit(x, y, steps=steps, max_features=x.shape[1])\n",
    "print(f\"With {len(final_est.estimators_)}: {train_scores[-1]} | {test_scores[-1]}\")\n",
    "plot_auc(steps, train_scores, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
